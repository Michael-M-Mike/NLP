{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Language Normalization**\n",
        "\n",
        "**Word normalization** is the task of putting words/tokens in a standard format, choosing a single normal form to represent words with multiple forms like \"USA\" and \"US\".\n",
        "\n",
        "This also includes **case folding**, which is the process of mapping everything to lowercase means that \"Woodchuck\" and \"woodchuck\" are represented identically.\n"
      ],
      "metadata": {
        "id": "kAzNlpDNprG4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Abstract\n",
        "\n",
        "This notebook explores text normalization methods and their implementation."
      ],
      "metadata": {
        "id": "wmbLseW0p2i_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">[Language Normalization](#folderId=1mMkxJ9aGYkHVPC6LfQ3j0xpAEfTgI_cq&updateTitle=true&scrollTo=kAzNlpDNprG4)\n",
        "\n",
        ">>[Abstract](#folderId=1mMkxJ9aGYkHVPC6LfQ3j0xpAEfTgI_cq&updateTitle=true&scrollTo=wmbLseW0p2i_)\n",
        "\n",
        ">>[Implementation](#folderId=1mMkxJ9aGYkHVPC6LfQ3j0xpAEfTgI_cq&updateTitle=true&scrollTo=M4MthiWl0KM6)\n",
        "\n",
        ">>[Lemmatization](#folderId=1mMkxJ9aGYkHVPC6LfQ3j0xpAEfTgI_cq&updateTitle=true&scrollTo=asLFACr0qT2r)\n",
        "\n",
        ">>>[Lemmatization with POS Tagging](#folderId=1mMkxJ9aGYkHVPC6LfQ3j0xpAEfTgI_cq&updateTitle=true&scrollTo=KkuLsRzetLx8)\n",
        "\n",
        ">>[Stemming](#folderId=1mMkxJ9aGYkHVPC6LfQ3j0xpAEfTgI_cq&updateTitle=true&scrollTo=JUXyuSOCqVag)\n",
        "\n",
        ">>[References](#folderId=1mMkxJ9aGYkHVPC6LfQ3j0xpAEfTgI_cq&updateTitle=true&scrollTo=CmJaPhyhp3n6)\n",
        "\n"
      ],
      "metadata": {
        "colab_type": "toc",
        "id": "qJec_hDup6FJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation"
      ],
      "metadata": {
        "id": "M4MthiWl0KM6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import pos_tag, word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"omw-1.4\")\n",
        "nltk.download(\"averaged_perceptron_tagger\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TJiiXBQrvmm",
        "outputId": "5e6b45be-9757-41a6-961f-3f97b5170f59"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lemmatization\n",
        "\n",
        "Lemmatization is the task of determining that two words have the same root, despite their surface differences. For example, the words \"sang\", \"sung\", and \"sings\" are all forms of the verb \"sing\". The word \"sing\" is the common lemma of these words, and a lemmatizer maps from all of them to \"sing\". \n",
        "\n",
        "Lemmatization is essential for processing morphologically complex languages."
      ],
      "metadata": {
        "id": "asLFACr0qT2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "sentences = [\n",
        "    \"I am booking the concert tickets!\",\n",
        "    \"The booking is cancelled.\"\n",
        "]\n",
        "\n",
        "for sentence in sentences:\n",
        "  for word in word_tokenize(sentence):\n",
        "    print(f\"{lemmatizer.lemmatize(word)}\", end=\" \")\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClTDWs_Lrigw",
        "outputId": "ba52ebe7-3a9c-4164-a239-9c90a13b8fe7"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am booking the concert ticket ! \n",
            "The booking is cancelled . \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lemmatization with POS Tagging\n",
        "\n",
        "`WordNetLemmatizer` can also take in an argument `pos` to understand the POS tag of the word/token because word-forms could be syntactically identical but contextually or semantically different. For example:\n",
        "\n",
        "```\n",
        "print(WordNetLemmatizer.lemmatize(\"booking\", pos=\"n\"))\n",
        "> Output: \"booking\"\n",
        "print(WordNetLemmatizer.lemmatize(\"booking\", pos=\"v\"))\n",
        "> Output: \"book\"\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "KkuLsRzetLx8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatization according to POS tagging\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "def pos_lemmatize(text):\n",
        "\n",
        "  # Tokenize the text into a list\n",
        "  words_list = word_tokenize(text)\n",
        "\n",
        "  # Iterate over text tokens\n",
        "  lemmatized_list = []\n",
        "  for word, tag in pos_tag(words_list):\n",
        "\n",
        "    # POS-based Lemmatization\n",
        "    if tag.startswith(\"J\"):\n",
        "        w = lemmatizer.lemmatize(word, pos=\"a\")\n",
        "    elif tag.startswith(\"V\"):\n",
        "        w = lemmatizer.lemmatize(word, pos=\"v\")\n",
        "    elif tag.startswith(\"N\"):\n",
        "        w = lemmatizer.lemmatize(word, pos=\"n\")\n",
        "    elif tag.startswith(\"R\"):\n",
        "        w = lemmatizer.lemmatize(word, pos=\"r\")\n",
        "    else:\n",
        "        w = word\n",
        "\n",
        "    lemmatized_list.append(w)\n",
        "\n",
        "  return \" \".join(lemmatized_list)"
      ],
      "metadata": {
        "id": "cF_LcIBQtrYn"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in sentences:\n",
        "  print(pos_lemmatize(sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLmXOphLyWJ6",
        "outputId": "38ffe3e9-233d-4323-d267-d416c4ad78d8"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I be book the concert ticket !\n",
            "The booking be cancel .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stemming\n",
        "\n",
        "Lemmatization algorithms can be too complex. For this reason, a simpler version is sometimes employed, that mainly just strips suffixes from the end of words. \n",
        "\n",
        "One of the most widely used stemming algorithms is the **Porter stemmer**."
      ],
      "metadata": {
        "id": "JUXyuSOCqVag"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dsi0DUcupkSc",
        "outputId": "55bfa0ab-c240-4da2-99bd-8aa5df5586d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i am book the concert ticket ! \n",
            "the book is cancel . \n"
          ]
        }
      ],
      "source": [
        "stemmer = PorterStemmer()\n",
        "\n",
        "for sentence in sentences:\n",
        "  for word in word_tokenize(sentence):\n",
        "    print(f\"{stemmer.stem(word)}\", end=\" \")\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "\n",
        "1. *Dan Jurafsky and James H. Martin. [Speech and Language Processing](https://web.stanford.edu/~jurafsky/slp3/) (3rd ed. draft).*\n",
        "\n",
        "2. NLTK's Documentation for [WordNetLemmatizer](https://www.nltk.org/api/nltk.stem.wordnet.html), [POS Tagger](https://www.nltk.org/api/nltk.tag.html), and [PorterStemmer](https://www.nltk.org/howto/stem.html). "
      ],
      "metadata": {
        "id": "CmJaPhyhp3n6"
      }
    }
  ]
}